{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB   \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6614 49412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-33024688b72e>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_sample['URL'][data_sample.URL != 0] = 1\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('clean_data.csv')\n",
    "\n",
    "data_sample = data\n",
    "# replace URL with 0 or 1\n",
    "data_sample['URL'] = data_sample['URL'].replace(np.nan, 0)\n",
    "data_sample['URL'][data_sample.URL != 0] = 1\n",
    "\n",
    "# nr of URL and non-URL\n",
    "print(len(data_sample['URL'][data_sample.URL == 1]),len(data_sample['URL'][data_sample.URL == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data_sample['URL']\n",
    "text =data_sample['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Text + Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Text (read on the link)\n",
    "path_fastText = '/Users/vilhelmbureviksandberg/Downloads/wiki-news-300d-1M.vec'\n",
    "\n",
    "dictionary = open(path_fastText, 'r', encoding='utf-8',\n",
    "                  newline='\\n', errors='ignore')\n",
    "\n",
    "embeds = {}\n",
    "for line in dictionary:\n",
    "    tokens = line.rstrip().split(' ')\n",
    "    embeds[tokens[0]] = [float(x) for x in tokens[1:]]\n",
    "    \n",
    "    if len(embeds) == 100000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedding, takes along time to run for large documents \n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "array_length = 20 * 300\n",
    "embedding_features = pd.DataFrame()\n",
    "for document in text:\n",
    "    # Saving the first 20 words of the document as a sequence\n",
    "    words = text_to_word_sequence(document)[0:20] \n",
    "    \n",
    "    # Retrieving the vector representation of each word and \n",
    "    # appending it to the feature vector \n",
    "    feature_vector = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            feature_vector = np.append(feature_vector, \n",
    "                                       np.array(embeds[word]))\n",
    "        except KeyError:\n",
    "            # In the event that a word is not included in our \n",
    "            # dictionary skip that word\n",
    "            pass\n",
    "    # If the text has less then 20 words, fill remaining vector with\n",
    "    # zeros\n",
    "    zeroes_to_add = array_length - len(feature_vector)\n",
    "    feature_vector = np.append(feature_vector, \n",
    "                               np.zeros(zeroes_to_add)\n",
    "                               ).reshape((1,-1))\n",
    "    \n",
    "    # Append the document feature vector to the feature table\n",
    "    embedding_features = embedding_features.append( \n",
    "                                     pd.DataFrame(feature_vector))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels from strings to binary\n",
    "le = LabelEncoder()\n",
    "le.fit(label)\n",
    "label = le.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 70/30 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(embedding_features, label, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train,y_train,model):\n",
    "    \n",
    "    if model == 'naive_bayes':\n",
    "        param_grid = [{'alpha':[10e-5,10e-3,10e-1,1]}]\n",
    "        kfold = StratifiedKFold(n_splits=10,shuffle = True, random_state = 1)\n",
    "        grid = GridSearchCV(BernoulliNB(),param_grid,cv=kfold,scoring='accuracy')\n",
    "        grid.fit(X_train,y_train)\n",
    "        grid_values = list(grid.best_params_.values())\n",
    "        clf = BernoulliNB(alpha = grid_values[0])\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        return clf\n",
    "    \n",
    "\n",
    "    if model == 'Linear_SGD_classifier':\n",
    "        param_grid = [{'alpha':[0.0001,0.001,0.01,0.1,1]}]\n",
    "        kfold = StratifiedKFold(n_splits=10,shuffle = True, random_state = 1)\n",
    "        grid = GridSearchCV(SGDClassifier(loss = 'squared_loss'),param_grid,cv=kfold,scoring='accuracy')\n",
    "        grid.fit(X_train,y_train)\n",
    "        grid_values = list(grid.best_params_.values())   \n",
    "        clf = SGDClassifier(loss = 'squared_loss',alpha = grid_values[0])\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        return clf\n",
    "    \n",
    "    if model == 'support_vector_machine':\n",
    "        param_grid = [{'C':[0.001, 0.01, 0.1,1,5,100],'gamma':[0.001,0.01,0.1,1,5,15]}]\n",
    "        kfold = StratifiedKFold(n_splits=10,shuffle = True, random_state = 1)\n",
    "        grid = GridSearchCV(SVC(), param_grid=param_grid, cv=kfold,scoring='accuracy')\n",
    "        grid.fit(X_train,y_train)\n",
    "        grid_values = list(grid.best_params_.values())   \n",
    "        clf = SVC(C=grid_values[1],gamma=grid_values[0], probability = True)\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "embeded_model1 = train_models(X_train,y_train,'naive_bayes')\n",
    "embeded_prediction1 = embeded_model1.predict(embedding_features)\n",
    "\n",
    "#SGD\n",
    "embeded_model2 = train_models(X_train,y_train,'Linear_SGD_classifier')\n",
    "embeded_prediction2 = embeded_model2.predict(embedding_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = pd.DataFrame(index = ['Word Embedding'], \n",
    "#          columns = ['Precision', 'Recall', 'F1 score', 'support']\n",
    "#          )\n",
    "#results.loc['Word Embedding'] = precision_recall_fscore_support(\n",
    "#        embedding_features,\n",
    "#          embeded_prediction,\n",
    "#        average = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-192-448775f5d77b>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Prediction'] = embeded_prediction\n"
     ]
    }
   ],
   "source": [
    "data['Prediction'] = embeded_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file \n",
    "data.to_csv(\"Problem1.csv\",encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some extra evaluation metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that create the perfomance table for training models \n",
    "def performance_table(X_train,y_train):\n",
    "    acc_list = []\n",
    "    clf_nb = train_models(X_train,y_train,'naive_bayes')\n",
    "    acc_nb = round(clf_nb.score(X_train,y_train) * 100, 2)\n",
    "    \n",
    "    clf_sgd = train_models(X_train,y_train,'Linear_SGD_classifier')\n",
    "    acc_sgd = round(clf_sgd.score(X_train,y_train) * 100, 2)   \n",
    "    \n",
    "    clf_svm = train_models(X_train,y_train,'support_vector_machine')\n",
    "    acc_svm = round(clf_svm.score(X_train,y_train) * 100, 2)\n",
    "    \n",
    "    acc_list.extend([acc_nb,acc_random_forest,acc_svm])\n",
    "    return acc_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
